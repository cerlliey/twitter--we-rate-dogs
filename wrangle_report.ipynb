{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d89eb0",
   "metadata": {},
   "source": [
    "<h1><center>Wrangle Report!</center></h1>\n",
    "<h3><center>We rate dogs!</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ba702",
   "metadata": {},
   "source": [
    "<center><b>Udacity project - September 2022</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6c797",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a1b38",
   "metadata": {},
   "source": [
    "The purpose of this project is to put to practices what I've learnt in lesson 3 of udacity data analysis nano degree course (data wrangling). The data set wrangled is twitter-archive-enhanced.csv AKA we rate dogs\n",
    "We rate dogs is a twitter account that rate dogs online. This rating usualy have a denominator of 10. This report briefly describe my effort in wrangling the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54213511",
   "metadata": {},
   "source": [
    "#### Data wrangling steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9174f5",
   "metadata": {},
   "source": [
    "- Data gathering\n",
    "- Assessing the data\n",
    "- Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577cb71",
   "metadata": {},
   "source": [
    "### Details of steps taken in wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b0381",
   "metadata": {},
   "source": [
    "**1- Data gathering**\n",
    "For this project, 3 datas are required and they are downloaded in different ways\n",
    "- twitter-archive-enhanced.csv : This is a data provided by udacity and was downloaded directly from the classroom page\n",
    "- image_predictions.tsv : this file was downloaded programatically using the requests library. Download link was provided in the classroom page\n",
    "- Twitter api/Json file : using tweets id in twitter-archive-enhanced.csv I queryed each tweet in the api. Unfortunately, I couldn't get the api key, so I checked the code provided and the json file provided in the classroom to make it work and have values in my json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f5ee53",
   "metadata": {},
   "source": [
    "### 2 - Assessing data\n",
    "After accessing the required data, I started by assessing them to see the data type in each rows and columns to know what and how to clean the data. Some functions used during this process are;\n",
    "- .head()\n",
    "- .info()\n",
    "- .shape\n",
    "- .dtypes\n",
    "- .describe() &\n",
    "- .value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0687c",
   "metadata": {},
   "source": [
    "### 3 - Data cleaning\n",
    "After accessing the data, the next thing to do is clean the data to make analysis easy. **The first thing I did was to make a copy of the original data to prevent damaging the data while working in the process**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Quality for each files include:**\n",
    "\n",
    "\n",
    "**twitter-archive-enhanced.csv**\n",
    "\n",
    "\n",
    "- Keep only original ratings that have images.\n",
    "- Delete columns that wonâ€™t be used for the analysis.\n",
    "- Separate timestamp into day -month -year.\n",
    "- Correct numerators.\n",
    "- Correct denominators more than 10.\n",
    "- Correct the incorrect dogs names\n",
    "\n",
    "**image_prediction**\n",
    "\n",
    "- Drop the duplication.\n",
    "- Create one column for the prediction and other one for the confidence level.\n",
    "- Delete the unused columns.\n",
    "\n",
    "**tweet_json**\n",
    "\n",
    "- Keep original tweets only\n",
    "\n",
    "**Tidiness**\n",
    "\n",
    " - Change tweet_id to type interger from object type "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2140d8",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "I had few challenges while cleaning my data, these challenges include:\n",
    "- getting a twitter api key\n",
    "- I initally didn't understand how to query the json file until it was explained better to me \n",
    "- the rating value in my dataset was missing, I had to analyse without rating which limited my analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b724f",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Having working with excel, I prefer to clean data programatically using python than doing it manualy which takes time and effort. if there was an issue while cleaning, I could easily revert back without loss of data. I also appreciate the packages that has been made available in python to make life easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5361f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
